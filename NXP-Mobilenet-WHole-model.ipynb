{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844ce5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(tf.__version__)\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d9755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Dropout, MaxPool2D, Dense, Conv2D, Flatten, BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e69bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddd0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3558897114153677129\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3044750132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14341431770952585801\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc79544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size\n",
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return str(round(size / 1024, 3))\n",
    "    elif unit == \"MB\":\n",
    "        return str(round(size / (1024 * 1024), 3)) \n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54322b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device=tf.test.gpu_device_name()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86df73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373b54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_img_size=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f5f511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c2741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:500]\n",
    "y_train=y_train[:500]\n",
    "x_test=x_test[:500]\n",
    "y_test=y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e981c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016b8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3,\n",
       "       6, 6, 2, 6, 3, 5, 4, 0, 0, 9, 1, 3, 4, 0, 3, 7, 3, 3, 5, 2, 2, 7,\n",
       "       1, 1, 1, 2, 2, 0, 9, 5, 7, 9, 2, 2, 5, 2, 4, 3, 1, 1, 8, 2, 1, 1,\n",
       "       4, 9, 7, 8, 5, 9, 6, 7, 3, 1, 9, 0, 3, 1, 3, 5, 4, 5, 7, 7, 4, 7,\n",
       "       9, 4, 2, 3, 8, 0, 1, 6, 1, 1, 4, 1, 8, 3, 9, 6, 6, 1, 8, 5, 2, 9,\n",
       "       9, 8, 1, 7, 7, 0, 0, 6, 9, 1, 2, 2, 9, 2, 6, 6, 1, 9, 5, 0, 4, 7,\n",
       "       6, 7, 1, 8, 1, 1, 2, 8, 1, 3, 3, 6, 2, 4, 9, 9, 5, 4, 3, 6, 7, 4,\n",
       "       6, 8, 5, 5, 4, 3, 1, 8, 4, 7, 6, 0, 9, 5, 1, 3, 8, 2, 7, 5, 3, 4,\n",
       "       1, 5, 7, 0, 4, 7, 5, 5, 1, 0, 9, 6, 9, 0, 8, 7, 8, 8, 2, 5, 2, 3,\n",
       "       5, 0, 6, 1, 9, 3, 6, 9, 1, 3, 9, 6, 6, 7, 1, 0, 9, 5, 8, 5, 2, 9,\n",
       "       0, 8, 8, 0, 6, 9, 1, 1, 6, 3, 7, 6, 6, 0, 6, 6, 1, 7, 1, 5, 8, 3,\n",
       "       6, 6, 8, 6, 8, 4, 6, 6, 1, 3, 8, 3, 4, 1, 7, 1, 3, 8, 5, 1, 1, 4,\n",
       "       0, 9, 3, 7, 4, 9, 9, 2, 4, 9, 9, 1, 0, 5, 9, 0, 8, 2, 1, 2, 0, 5,\n",
       "       6, 3, 2, 7, 8, 8, 6, 0, 7, 9, 4, 5, 6, 4, 2, 1, 1, 2, 1, 5, 9, 9,\n",
       "       0, 8, 4, 1, 1, 6, 3, 3, 9, 0, 7, 9, 7, 7, 9, 1, 5, 1, 6, 6, 8, 7,\n",
       "       1, 3, 0, 3, 3, 2, 4, 5, 7, 5, 9, 0, 3, 4, 0, 4, 4, 6, 0, 0, 6, 6,\n",
       "       0, 8, 1, 6, 2, 9, 2, 5, 9, 6, 7, 4, 1, 8, 7, 3, 6, 9, 3, 0, 4, 0,\n",
       "       5, 1, 0, 3, 4, 8, 5, 4, 7, 2, 3, 9, 7, 6, 7, 1, 4, 7, 0, 1, 7, 3,\n",
       "       1, 8, 4, 4, 2, 0, 2, 2, 0, 0, 9, 0, 9, 6, 8, 2, 7, 7, 4, 0, 3, 0,\n",
       "       8, 9, 4, 2, 7, 2, 5, 2, 5, 1, 9, 4, 8, 5, 1, 7, 4, 4, 0, 6, 9, 0,\n",
       "       7, 8, 8, 9, 9, 3, 3, 4, 0, 4, 5, 6, 6, 0, 1, 0, 8, 0, 4, 8, 8, 1,\n",
       "       5, 2, 6, 8, 1, 0, 0, 7, 7, 5, 9, 6, 2, 8, 3, 4, 7, 3, 9, 0, 1, 2,\n",
       "       4, 8, 1, 8, 6, 4, 4, 5, 7, 1, 3, 9, 8, 0, 1, 7], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267d42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741a6a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41450cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ffb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images,img_size):\n",
    "    resized_images = []\n",
    "    \n",
    "    for i in tqdm(range(len(images))):\n",
    "        resized_images.append(resize(images[i],(img_size),mode = 'constant'))\n",
    "    \n",
    "    return np.array(resized_images,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83e1324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data for MobileNet :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:05<00:00, 94.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data for MobileNet :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:05<00:00, 94.34it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Loading train data for MobileNet :')\n",
    "x_train = resize_images(x_train,mobilenet_img_size)\n",
    "\n",
    "print('Loading test data for MobileNet :')\n",
    "x_test = resize_images(x_test,mobilenet_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1a7d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "x_train=x_train / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "x_test=x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "958cd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3517d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd5e13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d45f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 112, 112, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 64)      2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 56, 56, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                4014090   \n",
      "=================================================================\n",
      "Total params: 4,027,658\n",
      "Trainable params: 4,027,018\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def mobilnet_block (x, filters, strides):\n",
    "    \n",
    "    x = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    return x\n",
    "#stem of the model\n",
    "input = Input(shape = (224,224,3))\n",
    "x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "# main part of the model\n",
    "x = mobilnet_block(x, filters = 64, strides = 1)\n",
    "x = mobilnet_block(x, filters = 128, strides = 2)\n",
    "# x = mobilnet_block(x, filters = 128, strides = 1)\n",
    "# x = mobilnet_block(x, filters = 256, strides = 2)\n",
    "# x = mobilnet_block(x, filters = 256, strides = 1)\n",
    "# x = mobilnet_block(x, filters = 512, strides = 2)\n",
    "# for _ in range (5):\n",
    "#      x = mobilnet_block(x, filters = 512, strides = 1)\n",
    "# x = mobilnet_block(x, filters = 1024, strides = 2)\n",
    "# x = mobilnet_block(x, filters = 1024, strides = 1)\n",
    "# x = AvgPool2D (pool_size = 7, strides = 1, data_format='channels_first')(x)\n",
    "x=Flatten()(x)\n",
    "output = Dense (units = 10, activation = 'softmax')(x)\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e57be674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_img_size=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13622dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90bf887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "971f73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04d34ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "            loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a67b77d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 224, 224, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f2f64fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([500, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3316bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 20s 629ms/step - loss: 1.2693 - acc: 0.7980\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 19s 607ms/step - loss: 1.0478 - acc: 0.8580\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 20s 613ms/step - loss: 0.6189 - acc: 0.8680\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 20s 610ms/step - loss: 0.8317 - acc: 0.8780\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 20s 632ms/step - loss: 0.4163 - acc: 0.9160\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 21s 651ms/step - loss: 0.4633 - acc: 0.9240\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 21s 673ms/step - loss: 0.3677 - acc: 0.9380\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 22s 697ms/step - loss: 0.4680 - acc: 0.9240\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 24s 755ms/step - loss: 0.2559 - acc: 0.9560\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 20s 622ms/step - loss: 0.0550 - acc: 0.9860\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 21s 653ms/step - loss: 0.4197 - acc: 0.9460\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 22s 695ms/step - loss: 0.3388 - acc: 0.9440\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 25s 783ms/step - loss: 0.0975 - acc: 0.9760\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 25s 797ms/step - loss: 0.3225 - acc: 0.9520\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 23s 715ms/step - loss: 0.4156 - acc: 0.9580\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 23s 706ms/step - loss: 0.0398 - acc: 0.9920\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 23s 723ms/step - loss: 0.2776 - acc: 0.9660\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 22s 673ms/step - loss: 0.1737 - acc: 0.9720\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 22s 697ms/step - loss: 0.1533 - acc: 0.9700\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 21s 649ms/step - loss: 0.0639 - acc: 0.9880\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 21s 654ms/step - loss: 0.1897 - acc: 0.9660\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 21s 650ms/step - loss: 0.0356 - acc: 0.9920\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 21s 669ms/step - loss: 0.3435 - acc: 0.9520\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 23s 702ms/step - loss: 0.0338 - acc: 0.9920\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 22s 680ms/step - loss: 0.0743 - acc: 0.9920\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 22s 673ms/step - loss: 0.0593 - acc: 0.9900\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 22s 685ms/step - loss: 0.0586 - acc: 0.9900\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 23s 726ms/step - loss: 0.0898 - acc: 0.9840\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 22s 683ms/step - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 22s 675ms/step - loss: 6.5372e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 22s 675ms/step - loss: 0.0393 - acc: 0.9940\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 22s 675ms/step - loss: 0.0659 - acc: 0.9900\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 22s 700ms/step - loss: 0.0643 - acc: 0.9760\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 22s 678ms/step - loss: 0.0464 - acc: 0.9920\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 22s 677ms/step - loss: 0.0117 - acc: 0.9980\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 23s 719ms/step - loss: 3.1132e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 23s 722ms/step - loss: 0.0704 - acc: 0.9880\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 21s 664ms/step - loss: 0.0237 - acc: 0.9940\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 22s 688ms/step - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 22s 689ms/step - loss: 0.0603 - acc: 0.9920\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 23s 707ms/step - loss: 0.0198 - acc: 0.9960\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 25s 778ms/step - loss: 0.0180 - acc: 0.9960\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 23s 707ms/step - loss: 0.0464 - acc: 0.9880\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 22s 676ms/step - loss: 7.5227e-04 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 22s 679ms/step - loss: 1.1474e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 21s 670ms/step - loss: 2.8614e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 22s 695ms/step - loss: 0.0638 - acc: 0.9920\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 24s 760ms/step - loss: 0.0233 - acc: 0.9980\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 21s 662ms/step - loss: 0.0779 - acc: 0.9900\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 23s 704ms/step - loss: 4.7408e-06 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    history = model.fit(x_train, y_train, batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,1)\n",
    "# ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
    "# legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "# ax[1].plot(history.history['acc'], color='b', label=\"Training Accuracy\")\n",
    "# legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the values from the validation dataset\n",
    "# y_pred = model.predict(x_test)\n",
    "# # Convert predictions classes to one hot vectors \n",
    "# y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "# # Convert validation observations to one hot vectors\n",
    "# y_true = np.argmax(y_test,axis = 1)\n",
    "# # compute the confusion matrix\n",
    "# confusion_mtx = tf.math.confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 9))\n",
    "# c = sns.heatmap(confusion_mtx, annot=True, fmt='g')\n",
    "# c.set(xticklabels=classes, yticklabels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06375dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MobileNet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cifar_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbce520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cifar_mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model(\"./cifar_mobilenet.h5\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da159177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"./cifar_mobilenet\")\n",
    "tflite_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a71bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"./cifar_mobilenet\")\n",
    "converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (500, 224,224,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (500, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_numpy = np.array(x_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ccd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f40bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (500, 224,224,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (500, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006791",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_quant_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2625f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_size = get_file_size(\"cifar_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\"\n",
    "open(TF_LITE_MODEL_FILE_NAME, \"wb\").write(tflite_model)\n",
    "keras_model_tflite_size=get_file_size(\"tf_lite_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_lite_float_16_model.tflite\"\n",
    "keras_model_tflite_quant_size=open(TF_LITE_MODEL_FLOAT_16_FILE_NAME, \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tf model accuracy:\",test_acc)\n",
    "print(\"tflite model accuracy:\",tflite_model_acc)\n",
    "print(\"tflite quant model accuracy:\",tflite_model_quant_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras model size\",convert_bytes(keras_model_size,\"KB\"))\n",
    "print(\"Keras tflite model size\",convert_bytes(keras_model_tflite_size,\"KB\"))\n",
    "print(\"Keras tflite quant model size\",convert_bytes(keras_model_tflite_quant_size,\"KB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model size\",convert_bytes(keras_model_size,\"MB\"))\n",
    "print(\"tflite model size\",convert_bytes(keras_model_tflite_size,\"MB\"))\n",
    "print(\"tflite quant model size\",convert_bytes(keras_model_tflite_quant_size,\"MB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82f64161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff75074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47688206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "quantize_layer_4 (QuantizeLa (None, 224, 224, 3)       3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 112, 112, 32)      961       \n",
      "_________________________________________________________________\n",
      "quant_batch_normalization (Q (None, 112, 112, 32)      129       \n",
      "_________________________________________________________________\n",
      "quant_re_lu (QuantizeWrapper (None, 112, 112, 32)      3         \n",
      "_________________________________________________________________\n",
      "quant_depthwise_conv2d (Quan (None, 112, 112, 32)      323       \n",
      "_________________________________________________________________\n",
      "quant_batch_normalization_1  (None, 112, 112, 32)      129       \n",
      "_________________________________________________________________\n",
      "quant_re_lu_1 (QuantizeWrapp (None, 112, 112, 32)      3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_1 (QuantizeWrap (None, 112, 112, 64)      2241      \n",
      "_________________________________________________________________\n",
      "quant_batch_normalization_2  (None, 112, 112, 64)      257       \n",
      "_________________________________________________________________\n",
      "quant_re_lu_2 (QuantizeWrapp (None, 112, 112, 64)      3         \n",
      "_________________________________________________________________\n",
      "quant_depthwise_conv2d_1 (Qu (None, 56, 56, 64)        643       \n",
      "_________________________________________________________________\n",
      "quant_batch_normalization_3  (None, 56, 56, 64)        257       \n",
      "_________________________________________________________________\n",
      "quant_re_lu_3 (QuantizeWrapp (None, 56, 56, 64)        3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrap (None, 56, 56, 128)       8577      \n",
      "_________________________________________________________________\n",
      "quant_batch_normalization_4  (None, 56, 56, 128)       513       \n",
      "_________________________________________________________________\n",
      "quant_re_lu_4 (QuantizeWrapp (None, 56, 56, 128)       3         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 401408)            1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                4014095   \n",
      "=================================================================\n",
      "Total params: 4,028,144\n",
      "Trainable params: 4,027,018\n",
      "Non-trainable params: 1,126\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MobileNet_model=tfmot.quantization.keras.quantize_model(model)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "MobileNet_model.compile(optimizer = opt , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "# Train\n",
    "MobileNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "110bda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])\n",
    "# with tf.device('/gpu:0'):\n",
    "#     history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7654a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 27s 804ms/step - loss: 2.3007 - accuracy: 0.0868\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 2.2746 - accuracy: 0.1182\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 2.2206 - accuracy: 0.1220\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 2.1538 - accuracy: 0.0722\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 2.1449 - accuracy: 0.0920\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 25s 789ms/step - loss: 1.9485 - accuracy: 0.1748\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 1.7855 - accuracy: 0.2029\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 1.6269 - accuracy: 0.2134\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 1.7119 - accuracy: 0.2566\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 1.5831 - accuracy: 0.2911\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 26s 800ms/step - loss: 1.3577 - accuracy: 0.3446\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 26s 800ms/step - loss: 0.7677 - accuracy: 0.7273\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.4848 - accuracy: 0.8496\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 25s 785ms/step - loss: 0.3726 - accuracy: 0.8862\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.2868 - accuracy: 0.9033\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 25s 784ms/step - loss: 0.2142 - accuracy: 0.9286\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 26s 801ms/step - loss: 0.1522 - accuracy: 0.9566\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.1525 - accuracy: 0.9681\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 25s 785ms/step - loss: 0.1370 - accuracy: 0.9613\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.1883 - accuracy: 0.9401\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 25s 796ms/step - loss: 0.1560 - accuracy: 0.9475\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.1786 - accuracy: 0.9502\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 25s 791ms/step - loss: 0.1107 - accuracy: 0.9585\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.1539 - accuracy: 0.9575\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.0936 - accuracy: 0.9835\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 0.0747 - accuracy: 0.9910\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 25s 789ms/step - loss: 0.0693 - accuracy: 0.9811\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 0.0537 - accuracy: 0.9912\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.1153 - accuracy: 0.9778\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.0496 - accuracy: 0.9871\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0359 - accuracy: 0.9954\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0321 - accuracy: 0.9941\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 25s 794ms/step - loss: 0.0759 - accuracy: 0.9779\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 25s 793ms/step - loss: 0.0623 - accuracy: 0.9827\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 25s 789ms/step - loss: 0.0202 - accuracy: 0.9959\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.0783 - accuracy: 0.9822\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 25s 791ms/step - loss: 0.0495 - accuracy: 0.9908\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 0.0379 - accuracy: 0.9861\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.0297 - accuracy: 0.9882\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0376 - accuracy: 0.9915\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 25s 794ms/step - loss: 0.0158 - accuracy: 0.9946\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 25s 791ms/step - loss: 0.0179 - accuracy: 0.9929\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 25s 791ms/step - loss: 0.0360 - accuracy: 0.9914\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0265 - accuracy: 0.9988\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.0414 - accuracy: 0.9879\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 25s 788ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 26s 794ms/step - loss: 0.0070 - accuracy: 0.9992\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 26s 797ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.0081 - accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    mobile = MobileNet_model.fit(x_train, y_train, batch_size = 16, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2080a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cifar_aware.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cifar_aware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_aware, test_acc_aware= model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8167ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"cifar_aware\")\n",
    "tflite_aware_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_aware_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 32, 32,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03145e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_aware_model_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_aware_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
