{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844ce5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(tf.__version__)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98d9755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Dropout, MaxPool2D, Dense, Conv2D, Flatten, BatchNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ddd0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7801351289072907850\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3044750132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7558917462786453108\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc79544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "    size = os.path.getsize(file_path)\n",
    "    return size\n",
    "def convert_bytes(size, unit=None):\n",
    "    if unit == \"KB\":\n",
    "        return str(round(size / 1024, 3))\n",
    "    elif unit == \"MB\":\n",
    "        return str(round(size / (1024 * 1024), 3)) \n",
    "    else:\n",
    "        return print('File size: ' + str(size) + ' bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54322b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device=tf.test.gpu_device_name()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86df73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373b54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_img_size=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96f5f511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c2741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train[:500]\n",
    "y_train=y_train[:500]\n",
    "x_test=x_test[:500]\n",
    "y_test=y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e981c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016b8d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3,\n",
       "       6, 6, 2, 6, 3, 5, 4, 0, 0, 9, 1, 3, 4, 0, 3, 7, 3, 3, 5, 2, 2, 7,\n",
       "       1, 1, 1, 2, 2, 0, 9, 5, 7, 9, 2, 2, 5, 2, 4, 3, 1, 1, 8, 2, 1, 1,\n",
       "       4, 9, 7, 8, 5, 9, 6, 7, 3, 1, 9, 0, 3, 1, 3, 5, 4, 5, 7, 7, 4, 7,\n",
       "       9, 4, 2, 3, 8, 0, 1, 6, 1, 1, 4, 1, 8, 3, 9, 6, 6, 1, 8, 5, 2, 9,\n",
       "       9, 8, 1, 7, 7, 0, 0, 6, 9, 1, 2, 2, 9, 2, 6, 6, 1, 9, 5, 0, 4, 7,\n",
       "       6, 7, 1, 8, 1, 1, 2, 8, 1, 3, 3, 6, 2, 4, 9, 9, 5, 4, 3, 6, 7, 4,\n",
       "       6, 8, 5, 5, 4, 3, 1, 8, 4, 7, 6, 0, 9, 5, 1, 3, 8, 2, 7, 5, 3, 4,\n",
       "       1, 5, 7, 0, 4, 7, 5, 5, 1, 0, 9, 6, 9, 0, 8, 7, 8, 8, 2, 5, 2, 3,\n",
       "       5, 0, 6, 1, 9, 3, 6, 9, 1, 3, 9, 6, 6, 7, 1, 0, 9, 5, 8, 5, 2, 9,\n",
       "       0, 8, 8, 0, 6, 9, 1, 1, 6, 3, 7, 6, 6, 0, 6, 6, 1, 7, 1, 5, 8, 3,\n",
       "       6, 6, 8, 6, 8, 4, 6, 6, 1, 3, 8, 3, 4, 1, 7, 1, 3, 8, 5, 1, 1, 4,\n",
       "       0, 9, 3, 7, 4, 9, 9, 2, 4, 9, 9, 1, 0, 5, 9, 0, 8, 2, 1, 2, 0, 5,\n",
       "       6, 3, 2, 7, 8, 8, 6, 0, 7, 9, 4, 5, 6, 4, 2, 1, 1, 2, 1, 5, 9, 9,\n",
       "       0, 8, 4, 1, 1, 6, 3, 3, 9, 0, 7, 9, 7, 7, 9, 1, 5, 1, 6, 6, 8, 7,\n",
       "       1, 3, 0, 3, 3, 2, 4, 5, 7, 5, 9, 0, 3, 4, 0, 4, 4, 6, 0, 0, 6, 6,\n",
       "       0, 8, 1, 6, 2, 9, 2, 5, 9, 6, 7, 4, 1, 8, 7, 3, 6, 9, 3, 0, 4, 0,\n",
       "       5, 1, 0, 3, 4, 8, 5, 4, 7, 2, 3, 9, 7, 6, 7, 1, 4, 7, 0, 1, 7, 3,\n",
       "       1, 8, 4, 4, 2, 0, 2, 2, 0, 0, 9, 0, 9, 6, 8, 2, 7, 7, 4, 0, 3, 0,\n",
       "       8, 9, 4, 2, 7, 2, 5, 2, 5, 1, 9, 4, 8, 5, 1, 7, 4, 4, 0, 6, 9, 0,\n",
       "       7, 8, 8, 9, 9, 3, 3, 4, 0, 4, 5, 6, 6, 0, 1, 0, 8, 0, 4, 8, 8, 1,\n",
       "       5, 2, 6, 8, 1, 0, 0, 7, 7, 5, 9, 6, 2, 8, 3, 4, 7, 3, 9, 0, 1, 2,\n",
       "       4, 8, 1, 8, 6, 4, 4, 5, 7, 1, 3, 9, 8, 0, 1, 7], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267d42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741a6a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41450cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(x_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ffb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images,img_size):\n",
    "    resized_images = []\n",
    "    \n",
    "    for i in tqdm(range(len(images))):\n",
    "        resized_images.append(resize(images[i],(img_size),mode = 'constant'))\n",
    "    \n",
    "    return np.array(resized_images,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e1324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data for MobileNet :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:05<00:00, 92.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data for MobileNet :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:05<00:00, 92.41it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Loading train data for MobileNet :')\n",
    "x_train = resize_images(x_train,mobilenet_img_size)\n",
    "\n",
    "print('Loading test data for MobileNet :')\n",
    "x_test = resize_images(x_test,mobilenet_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a7d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224,224,3)\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "x_train=x_train / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "x_test=x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958cd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3517d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5e13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d45f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e57be674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_img_size=(224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13622dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 8s 117ms/step - loss: 29.4245 - accuracy: 0.1482\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 6.9887 - accuracy: 0.1289\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 3s 101ms/step - loss: 2.8582 - accuracy: 0.0993\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 2.6098 - accuracy: 0.0763\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 3s 100ms/step - loss: 2.6039 - accuracy: 0.0899\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                501770    \n",
      "=================================================================\n",
      "Total params: 3,730,634\n",
      "Trainable params: 3,166,218\n",
      "Non-trainable params: 564,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(include_top=False, weights='imagenet',input_shape = mobilenet_img_size, classes=10)\n",
    "base_model.trainable = True \n",
    "\n",
    "for layer in base_model.layers[:50]:\n",
    "    layer.trainable =  False\n",
    "\n",
    "MobileNet_model = tf.keras.models.Sequential()\n",
    "MobileNet_model.add(base_model)\n",
    "MobileNet_model.add(Flatten())\n",
    "MobileNet_model.add(Dense(10,activation=('softmax')))\n",
    "\n",
    "early_stopping = EarlyStopping(min_delta = 0.001,patience = 20,restore_best_weights = True,verbose = 0)\n",
    "\n",
    "# Compile\n",
    "MobileNet_model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "# Train\n",
    "Mobile = MobileNet_model.fit(x_train, y_train, batch_size = 16, epochs = 5,callbacks = [early_stopping])\n",
    "\n",
    "MobileNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90bf887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "971f73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    \n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.5),\n",
    "#     tf.keras.layers.Dense(num_classes, activation='softmax'),\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3316bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/gpu:0'):\n",
    "#     history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "131c2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2,1)\n",
    "# ax[0].plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
    "# legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "# ax[1].plot(history.history['acc'], color='b', label=\"Training Accuracy\")\n",
    "# legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa28a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d14b5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the values from the validation dataset\n",
    "# y_pred = model.predict(x_test)\n",
    "# # Convert predictions classes to one hot vectors \n",
    "# y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "# # Convert validation observations to one hot vectors\n",
    "# y_true = np.argmax(y_test,axis = 1)\n",
    "# # compute the confusion matrix\n",
    "# confusion_mtx = tf.math.confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ff315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 9))\n",
    "# c = sns.heatmap(confusion_mtx, annot=True, fmt='g')\n",
    "# c.set(xticklabels=classes, yticklabels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06375dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MobileNet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cc2ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cifar_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dbce520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./cifar_mobilenet\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./cifar_mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86e4dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 76ms/step - loss: 4.5934 - accuracy: 0.1020\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"./cifar_mobilenet.h5\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da159177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                501770    \n",
      "=================================================================\n",
      "Total params: 3,730,634\n",
      "Trainable params: 3,166,218\n",
      "Non-trainable params: 564,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b88ec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10199999809265137"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06de53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"./cifar_mobilenet\")\n",
    "tflite_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3a71bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"./cifar_mobilenet\")\n",
    "converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc1f6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d12c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [500 224 224   3]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [500  10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (500, 224,224,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (500, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf90c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_numpy = np.array(x_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9da0c5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (500, 10)\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3674739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ccd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57d41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65a2dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [  1 224 224   3]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [ 1 10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c4f40bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: [500 224 224   3]\n",
      "Input Type: <class 'numpy.float32'>\n",
      "Output Shape: [500  10]\n",
      "Output Type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (500, 224,224,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (500, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6006791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results shape: (500, 10)\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e57c0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_quant_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2625f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_size = get_file_size(\"cifar_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6069f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\"\n",
    "open(TF_LITE_MODEL_FILE_NAME, \"wb\").write(tflite_model)\n",
    "keras_model_tflite_size=get_file_size(\"tf_lite_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d09a3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_lite_float_16_model.tflite\"\n",
    "keras_model_tflite_quant_size=open(TF_LITE_MODEL_FLOAT_16_FILE_NAME, \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ceb06c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf model accuracy: 0.10199999809265137\n",
      "tflite model accuracy: 0.102\n",
      "tflite quant model accuracy: 0.102\n"
     ]
    }
   ],
   "source": [
    "print(\"tf model accuracy:\",test_acc)\n",
    "print(\"tflite model accuracy:\",tflite_model_acc)\n",
    "print(\"tflite quant model accuracy:\",tflite_model_quant_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b3f6cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model size 39552.023\n",
      "Keras tflite model size 14455.184\n",
      "Keras tflite quant model size 7239.281\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras model size\",convert_bytes(keras_model_size,\"KB\"))\n",
    "print(\"Keras tflite model size\",convert_bytes(keras_model_tflite_size,\"KB\"))\n",
    "print(\"Keras tflite quant model size\",convert_bytes(keras_model_tflite_quant_size,\"KB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "225b2965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size 38.625\n",
      "tflite model size 14.116\n",
      "tflite quant model size 7.07\n"
     ]
    }
   ],
   "source": [
    "print(\"model size\",convert_bytes(keras_model_size,\"MB\"))\n",
    "print(\"tflite model size\",convert_bytes(keras_model_tflite_size,\"MB\"))\n",
    "print(\"tflite quant model size\",convert_bytes(keras_model_tflite_quant_size,\"MB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82f64161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fff75074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Function (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                501770    \n",
      "=================================================================\n",
      "Total params: 3,730,634\n",
      "Trainable params: 3,166,218\n",
      "Non-trainable params: 564,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNet(include_top=False, weights='imagenet',input_shape = mobilenet_img_size, classes=10)\n",
    "base_model.trainable = True \n",
    "# base_model=tfmot.quantization.keras.quantize_model(base_model)\n",
    "for layer in base_model.layers[:50]:\n",
    "    layer.trainable =  False\n",
    "\n",
    "MobileNet_model = tf.keras.models.Sequential()\n",
    "MobileNet_model.add(base_model)\n",
    "MobileNet_model.add(Flatten())\n",
    "MobileNet_model.add(Dense(10,activation=('softmax')))\n",
    "\n",
    "early_stopping = EarlyStopping(min_delta = 0.001,patience = 20,restore_best_weights = True,verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47688206",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Quantizing a tf.keras Model inside another tf.keras Model is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1fea3b452700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMobileNet_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfmot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMobileNet_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mMobileNet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"adam\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[1;34m(to_quantize)\u001b[0m\n\u001b[0;32m    138\u001b[0m         'Functional model.')\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m   \u001b[0mannotated_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mquantize_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotated_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize.py\u001b[0m in \u001b[0;36mquantize_annotate_model\u001b[1;34m(to_annotate)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mquantize_annotate_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQuantizeAnnotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m   return keras.models.clone_model(\n\u001b[0m\u001b[0;32m    225\u001b[0m       to_annotate, input_tensors=None, clone_function=_add_quant_wrapper)\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     return _clone_sequential_model(\n\u001b[0m\u001b[0;32m    428\u001b[0m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0;32m    429\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    329\u001b[0m     cloned_layer = (\n\u001b[0;32m    330\u001b[0m         \u001b[0m_clone_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         if isinstance(layer, InputLayer) else layer_fn(layer))\n\u001b[0m\u001b[0;32m    332\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[0mlayer_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcloned_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\quantize.py\u001b[0m in \u001b[0;36m_add_quant_wrapper\u001b[1;34m(layer)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m    219\u001b[0m           \u001b[1;34m'Quantizing a tf.keras Model inside another tf.keras Model is not supported.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       )\n",
      "\u001b[1;31mValueError\u001b[0m: Quantizing a tf.keras Model inside another tf.keras Model is not supported."
     ]
    }
   ],
   "source": [
    "MobileNet_model=tfmot.quantization.keras.quantize_model(MobileNet_model)\n",
    "MobileNet_model.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "# Train\n",
    "\n",
    "\n",
    "MobileNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "110bda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-06),\n",
    "#             loss='categorical_crossentropy', metrics=['acc'])\n",
    "# with tf.device('/gpu:0'):\n",
    "#     history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7654a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " The primary convolution algorithm failed memory allocation, while a secondary algorithm is not provided.\n\t [[node gradient_tape/sequential_1/mobilenet_1.00_224/quant_conv_pw_13/Conv2D/Conv2DBackpropFilter (defined at <ipython-input-58-7476d99938a4>:1) ]] [Op:__inference_train_function_81259]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_1/mobilenet_1.00_224/quant_conv_pw_13/Conv2D/Conv2DBackpropFilter:\n sequential_1/mobilenet_1.00_224/quant_conv_dw_13_relu/MovingAvgQuantize/FakeQuantWithMinMaxVars (defined at C:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\quant_ops.py:343)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-7476d99938a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMobile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMobileNet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  The primary convolution algorithm failed memory allocation, while a secondary algorithm is not provided.\n\t [[node gradient_tape/sequential_1/mobilenet_1.00_224/quant_conv_pw_13/Conv2D/Conv2DBackpropFilter (defined at <ipython-input-58-7476d99938a4>:1) ]] [Op:__inference_train_function_81259]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_1/mobilenet_1.00_224/quant_conv_pw_13/Conv2D/Conv2DBackpropFilter:\n sequential_1/mobilenet_1.00_224/quant_conv_dw_13_relu/MovingAvgQuantize/FakeQuantWithMinMaxVars (defined at C:\\conda\\envs\\ml\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\quant_ops.py:343)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "Mobile = MobileNet_model.fit(x_train, y_train, batch_size = 16, epochs = 5,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2080a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cifar_aware.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cifar_aware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss_aware, test_acc_aware= model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8167ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=tf.lite.TFLiteConverter.from_saved_model(\"cifar_aware\")\n",
    "tflite_aware_model=converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter= tf.lite.Interpreter(model_content=tflite_aware_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_details=interpreter.get_output_details()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 32, 32,3))\n",
    "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"Input Shape:\", input_details[0]['shape'])\n",
    "print(\"Input Type:\", input_details[0]['dtype'])\n",
    "print(\"Output Shape:\", output_details[0]['shape'])\n",
    "print(\"Output Type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03145e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
    "interpreter.invoke()\n",
    "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
    "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_aware_model_acc = accuracy_score(prediction_classes, np.argmax(y_test,axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_aware_model_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0a316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
